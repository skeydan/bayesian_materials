---
title: "Bayesian modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(gridExtra)
library(statsr)
library(BAS)
library(GGally)
```

### Load data

```{r load-data}
load("movies.Rdata")
```


* * *

## Part 1: Data

Our task is to predict the  audience score on Rotten Tomatoes from a set of movie features as well as metadata obtained from the IMDB and Rotten Tomatoes websites.
The data have been sampled at random, so the results will be generalizable; however, we will not be able to say anything about causality as this is an observation study (no random assignment was used).

Let's first inspect the dataset:

```{r}
head(movies)
```


* * *

## Part 2: Data manipulation

Before further exploring the data, let's first do some feature engineering...

```{r}
movies <- movies %>% mutate(
  feature_film = if_else(title_type == 'Feature Film', "yes", "no"),
  drama = if_else(genre == 'Drama', "yes", "no"),
  mpaa_rating_R = if_else(mpaa_rating == "R", "yes", "no"),
  oscar_season = if_else(thtr_rel_month %in% c(10,11,12), "yes", "no"),
  summer_season = if_else(thtr_rel_month %in% c(5,6,7,8), "yes", "no")
)
```

... and restrict the set of possible predictors to variables we think might be relevant:

```{r}
movies <- movies %>% select(
    audience_score, feature_film, drama, runtime, mpaa_rating_R, thtr_rel_year, oscar_season, summer_season,
    imdb_rating, imdb_num_votes, critics_score, best_pic_nom, best_pic_win, best_actor_win,
    best_actress_win, best_dir_win, top200_box
)
head(movies)
```


## Part 3: Exploratory data analysis

To get an idea about possible correlations, we plot audience_score against every hypothetical predictor:

```{r}
p1 <- ggplot(movies, aes(x = feature_film, y = audience_score)) + geom_boxplot()
p2 <- ggplot(movies, aes(x = drama, y = audience_score)) + geom_boxplot()
p3 <- ggplot(movies, aes(x = mpaa_rating_R, y = audience_score)) + geom_boxplot()
p4 <- ggplot(movies, aes(x = oscar_season, y = audience_score)) + geom_boxplot()
p5 <- ggplot(movies, aes(x = summer_season, y = audience_score)) + geom_boxplot()
p6 <- ggplot(movies, aes(x = runtime, y = audience_score)) + geom_point()
p7 <- ggplot(movies, aes(x = thtr_rel_year, y = audience_score)) + geom_point()
p8 <- ggplot(movies, aes(x = imdb_rating, y = audience_score)) + geom_point()
p9 <- ggplot(movies, aes(x = imdb_num_votes, y = audience_score)) + geom_point()
p10 <- ggplot(movies, aes(x = critics_score, y = audience_score)) + geom_point()
p11 <- ggplot(movies, aes(x = best_pic_nom, y = audience_score)) + geom_boxplot()
p12 <- ggplot(movies, aes(x = best_pic_win, y = audience_score)) + geom_boxplot()
p13 <- ggplot(movies, aes(x = best_actor_win, y = audience_score)) + geom_boxplot()
p14 <- ggplot(movies, aes(x = best_actress_win, y = audience_score)) + geom_boxplot()
p15 <- ggplot(movies, aes(x = best_dir_win, y = audience_score)) + geom_boxplot()
p16 <- ggplot(movies, aes(x = top200_box, y = audience_score)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4)
grid.arrange(p5,p6,p7,p8)
grid.arrange(p9,p10,p11,p12)
grid.arrange(p13,p14,p15,p16)
```

From the plots, we think that feature_film, critics_score and imdb_rating might be interesting, as well as possibly best_pic_win and best_pic_nom.
In addition to the plots, let's inspect audience_score means and variances for the categorical variables, and inspect the intercorrelations for the numerical ones. The latter will also show us which predictors are intercorrelated and how much so.

```{r}
movies %>% group_by(feature_film) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(drama) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(mpaa_rating_R) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(oscar_season) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(summer_season) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies_numeric <- movies %>% select(audience_score, runtime, thtr_rel_year, imdb_rating, imdb_num_votes, critics_score)
cor(movies_numeric, use = "complete.obs")
```

Not surprisingly, audience_score is highly correlated with imdb_rating and critics_score, but critics_score and audience_score are themselves highly correlated.

```{r}
movies %>% group_by(best_pic_nom) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(best_pic_win) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(best_actor_win) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(best_actress_win) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(best_dir_win) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```

```{r}
movies %>% group_by(top200_box) %>% summarise(mean = mean(audience_score), var = var(audience_score), cnt = n())
```



* * *

## Part 4: Modeling

Now, it's time to fit the models. We use a uniform prior over models and ZS-null prior for the coefficients.

```{r}
fit <- bas.lm(
  data = movies,
  formula = audience_score ~ . ,
  prior = "ZS-null",
  modelprior = uniform(),
  method = "BAS"
  )   
```

Let's directly look at the marginal posterior inclusion probabilities (pips) for the predictors.
All  predictors with pip > 0.5 would be included in the _median probability model_.
As we see, these are imdb_rating and critics_score (plus the intercept).
Interestingly, both are included, even though they are highly correlated (multicollinearity).


```{r}
plot(fit, which = 4) 
```


We can also get the pips printing the fit object returned, Of course, we see the same result as in the plot.

```{r}
fit
```

Now, let's look at the best 5 models (posterior probability-wise):

```{r}
summary(fit)
```

So the highest posterior probability model, just like the median probability model, includes the intercept, imdb_rating, and critics_score.
Looking at the Bayes factors, and the posterior probabilities, for the other models, we see that there is just one model that works as well as the best one (row 2). This additionally includes runtime.
However, the correlation between audience_score and runtime is low, and this is anyway just the second best model, so there is no reason to include this additional predictor (uselessly inflating the number of parameters in the model.)

So we'll stick with predictors critics_score and imdb_rating.
Let's look at posterior probabilities and confidence intervals for these:

```{r}
plot(coef(fit), subset=c(9,11))
```

Both parameters are _very_ unlikely to be 0. We also see this from the confidence intervals.

```{r}
plot(confint(coef(fit), parm=c(9,11)))
```


* * *

## Part 5: Prediction

Now, let's try predicting audience_score for a new movie. 
We construct the movie by setting thtr_rel_year to 2016, choosing "yes" for all categorical variables and using the respective variable mean from the movies dataset for the numerical variables.

```{r}
movies_new <- data_frame(
  audience_score=mean(movies$audience_score),
  feature_film=factor("yes", levels = c("yes","no")),
  drama=factor("yes", levels = c("yes","no")),
  runtime=mean(na.omit(movies$runtime)),
  mpaa_rating_R=factor("yes", levels = c("yes","no")),
  thtr_rel_year=2016,
  oscar_season=factor("yes", levels = c("yes","no")),
  summer_season=factor("yes", levels = c("yes","no")),
  imdb_rating=mean(movies$imdb_rating),
  imdb_num_votes=mean(movies$imdb_num_votes),
  critics_score=mean(movies$critics_score),
  best_pic_win=factor("yes", levels = c("yes","no")),
  best_pic_nom=factor("yes", levels = c("yes","no")),
  best_actor_win=factor("yes", levels = c("yes","no")),
  best_actress_win=factor("yes", levels = c("yes","no")),
  best_dir_win=factor("yes", levels = c("yes","no")),
  top200_box=factor("yes", levels = c("yes","no"))
)
movies_new
  
```


We will compare predictions from
* the highest posterior probability model (HPM),
* Bayesian model averaging (BMA),
* the median probability model (MPM), and
* best predictive model (BPM).

```{r}
HPM = predict(fit, movies_new, estimator="HPM")
print(HPM$fit[1])
(fit$namesx[attr(HPM$fit, 'model') +1])
```

```{r}
MPM = predict(fit, estimator="MPM")
(fit$namesx[attr(MPM$fit, 'model') +1])[-1]
```

```{r}
BMA = predict(fit, estimator="BMA")
(fit$namesx[attr(BMA$fit, 'model') +1])[-1]
```

```{r}
BPM = predict(fit, estimator="BPM")
(fit$namesx[attr(BPM$fit, 'model') +1])[-1]
```

```{r}
ggpairs(data.frame(HPM = as.vector(HPM$fit),  #this used predict so we need to extract fitted values
                   MPM = as.vector(MPM$fit),  # this used fitted
                   BPM = as.vector(BPM$fit),  # this used fitted
                   BMA = as.vector(BMA$fit))) # this used predict

```


* * *

## Part 6: Conclusion

